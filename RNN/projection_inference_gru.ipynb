{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae03972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"Choose RNN module: LSTM or GRU\")\n",
    "# parser.add_argument(\"--rnn_module\", type=str, default=\"LSTM\", help=\"Choose RNN module: LSTM or GRU\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "rnn = \"GRU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# Import the single DOF finite difference model MLP model\n",
    "from mlp_singledof_rnn import MLP, MLPProjectionFilter, CustomGRULayer, GRU_Hidden_State, CustomLSTMLayer, LSTM_Hidden_State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155089d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform_trajectories(key, var_min, var_max, dataset_size, nvar):\n",
    "    rng = np.random.default_rng(seed=key)\n",
    "    xi_samples = rng.uniform(\n",
    "        low=var_min,\n",
    "        high=var_max,\n",
    "        size=(dataset_size, nvar)\n",
    "    )\n",
    "    return xi_samples, rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for MLP model\n",
    "\n",
    "num_batch = 1000\n",
    "num_dof=1\n",
    "num_steps=50\n",
    "timestep=0.05\n",
    "v_max=1.0\n",
    "a_max=2.0\n",
    "j_max=5.0\n",
    "p_max=180.0*np.pi/180.0 \n",
    "theta_init=0.0\n",
    "\n",
    "# vmax = 1.0\n",
    "# num_batch = 1000\n",
    "# nvar = 1\n",
    "nvar_single = num_steps\n",
    "nvar = num_dof * nvar_single\n",
    "theta_init_min=0.0\n",
    "theta_init_max=2*np.pi\n",
    "\n",
    "\n",
    "#calculating number of constraints\n",
    "num_acc = num_steps - 1\n",
    "num_jerk = num_acc - 1\n",
    "num_pos = num_steps\n",
    "num_vel_constraints = 2 * num_steps * num_dof\n",
    "num_acc_constraints = 2 * num_acc * num_dof\n",
    "num_jerk_constraints = 2 * num_jerk * num_dof\n",
    "num_pos_constraints = 2 * num_pos * num_dof\n",
    "num_total_constraints = (num_vel_constraints + num_acc_constraints + \n",
    "                            num_jerk_constraints + num_pos_constraints)\n",
    "\n",
    "dataset_size = num_batch#200000\n",
    "#Maximum Iterations\n",
    "maxiter_projection = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aac9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "#For training\n",
    "theta_init, rng_theta_init = sample_uniform_trajectories(41, var_min= theta_init_min, var_max = theta_init_max, dataset_size=dataset_size, nvar=1)\n",
    "#print(\"theta_init\", theta_init.shape)\n",
    "v_start, rng_v_start = sample_uniform_trajectories(40, var_min =-0.8*v_max, var_max = 0.8*v_max, dataset_size=dataset_size, nvar=1)\n",
    "#print(\"v_start\", v_start.shape)\n",
    "v_goal, rng_v_goal = sample_uniform_trajectories(39, var_min =-0.8*v_max, var_max = 0.8*v_max, dataset_size=dataset_size, nvar=1)\n",
    "\n",
    "## USe constant value of theta_init, v_start and v_goal for inference:\n",
    "\n",
    "theta_init_scalar = 90.0*np.pi/180.0\n",
    "v_start_scalar = 0.0\n",
    "v_goal_scalar = -0.3\n",
    "theta_init = np.tile(theta_init_scalar, (dataset_size,1))\n",
    "v_start = np.tile(v_start_scalar, (dataset_size,1))\n",
    "v_goal = np.tile(v_goal_scalar, (dataset_size,1))\n",
    "\n",
    "\n",
    "\n",
    "#For training\n",
    "xi_samples, rng = sample_uniform_trajectories(42, var_min=-v_max, var_max=v_max ,dataset_size=dataset_size, nvar=nvar)\n",
    "\n",
    "\n",
    "inp = np.hstack(( xi_samples, theta_init, v_start, v_goal))\n",
    "\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fcc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rnn == \"GRU\":\n",
    "    print(\"Training with GRU\")\n",
    "    #GRU handling\n",
    "    rnn = \"GRU\"\n",
    "    gru_input_size = 3*num_total_constraints+3*nvar\n",
    "    # print(gru_input_size)\n",
    "    gru_hidden_size = 512\n",
    "    # gru_output_size = (2*nvar)**2+2*nvar\n",
    "    gru_output_size = num_total_constraints+nvar\n",
    "    # gru_context_size = mlp_planner_inp_dim\n",
    "\n",
    "    gru_context = CustomGRULayer(gru_input_size, gru_hidden_size, gru_output_size)\n",
    "\n",
    "    rnn_context = gru_context\n",
    "\n",
    "\n",
    "    input_hidden_state_init = np.shape(inp)[1]\n",
    "    mid_hidden_state_init = 512\n",
    "    out_hidden_state_init = gru_hidden_size\n",
    "\n",
    "    gru_init  =  GRU_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "    \n",
    "    rnn_init = gru_init\n",
    "    ##\n",
    "elif rnn == \"LSTM\":\n",
    "    print(\"Training with LSTM\")\n",
    "    #LSTM handling\n",
    "    rnn = \"LSTM\"\n",
    "    lstm_input_size = 3*num_total_constraints+3*nvar\n",
    "    # print(lstm_input_size)\n",
    "    lstm_hidden_size = 512\n",
    "    # lstm_output_size = (2*nvar)**2+2*nvar\n",
    "    lstm_output_size = num_total_constraints+nvar\n",
    "    # lstm_context_size = mlp_planner_inp_dim\n",
    "\n",
    "    lstm_context = CustomLSTMLayer(lstm_input_size, lstm_hidden_size, lstm_output_size)\n",
    "\n",
    "    rnn_context = lstm_context\n",
    "\n",
    "    input_hidden_state_init = np.shape(inp)[1]\n",
    "    mid_hidden_state_init = 512\n",
    "    out_hidden_state_init = lstm_hidden_size\n",
    "\n",
    "    lstm_init = LSTM_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "\n",
    "    rnn_init = lstm_init\n",
    "\n",
    "    ##\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc_inp_dim = np.shape(inp)[1] \n",
    "mlp_inp_dim = enc_inp_dim\n",
    "hidden_dim = 1024\n",
    "mlp_out_dim = 2*nvar + num_total_constraints #( xi_samples- 0:nvar, lamda_smples- nvar:2*nvar)\n",
    "\n",
    "mlp =  MLP(mlp_inp_dim, hidden_dim, mlp_out_dim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MLPProjectionFilter(mlp=mlp,rnn_context=rnn_context, rnn_init=rnn_init, num_batch = num_batch,num_dof=num_dof,num_steps=num_steps,\n",
    "\t\t\t\t\t\t\ttimestep=timestep,v_max=v_max,a_max=a_max,j_max=j_max,p_max=p_max, \n",
    "\t\t\t\t\t\t\tmaxiter_projection=maxiter_projection, rnn=rnn).to(device)\n",
    "\n",
    "print(type(model))\n",
    "\n",
    "model.load_state_dict(torch.load(f'./training_weights/mlp_learned_single_dof_{rnn}.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "#Generate Test Data\n",
    "\n",
    "\n",
    "inp_test = inp\n",
    "inp_test = torch.tensor(inp_test).float()\n",
    "inp_test = inp_test.to(device)\n",
    "inp_mean = inp_test.mean()\n",
    "inp_std = inp_test.std()\n",
    "# inp_test = torch.vstack([inp_test] * num_batch)\n",
    "inp_norm_test = (inp_test - inp_mean) / inp_std\n",
    "\n",
    "xi_samples_input_nn_test = inp_test\n",
    "\n",
    "theta_init_test = torch.from_numpy(theta_init).float().to(device)\n",
    "v_start_test = torch.from_numpy(v_start).float().to(device)\n",
    "v_goal_test = torch.from_numpy(v_goal).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xi_projected, avg_res_fixed_point, avg_res_primal, res_primal_history, res_fixed_point_history = model.decoder_function(inp_norm_test, xi_samples_input_nn_test,\n",
    "                                                                                                                            theta_init_test, v_start_test, \n",
    "                                                                                                                            v_goal_test, rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a97a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy for analysis\n",
    "xi_np = np.array(xi_samples)\n",
    "xi_filtered_np = np.array(xi_projected.cpu().detach().numpy())\n",
    "prime_residuals_np = np.array(res_primal_history.cpu().detach().numpy())\n",
    "fixed_residuals_np = np.array(res_fixed_point_history.cpu().detach().numpy())\n",
    "# Print convergence statistics\n",
    "print(f\"\\nConvergence Statistics:\")\n",
    "# print(f\"Final primal residual - Mean: {np.mean(prime_residuals_np[-1]):.6f}, Max: {np.max(prime_residuals_np[-1]):.6f}\")\n",
    "# print(f\"Final fixed point residual - Mean: {np.mean(fixed_residuals_np[-1]):.6f}, Max: {np.max(fixed_residuals_np[-1]):.6f}\")\n",
    "\n",
    "print(f\"Prime residuals shape: {prime_residuals_np.shape}\")\n",
    "print(f\"Fixed point residuals shape: {fixed_residuals_np.shape}\")\n",
    "\n",
    "#Save\n",
    "os.makedirs('results_{rnn}_inference', exist_ok=True)\n",
    "\n",
    "#Start\n",
    "print(\"Start\")\n",
    "print(f\"Max Prime residuals start: {max(prime_residuals_np[0])}\")\n",
    "print(f\"Max fixed residuals start: {max(fixed_residuals_np[0])}\")\n",
    "print(f\"Min Prime residuals start: {min(prime_residuals_np[0])}\")\n",
    "print(f\"Min fixed residuals start: {min(fixed_residuals_np[0])}\")\n",
    "\n",
    "#End\n",
    "print(\"End\")\n",
    "print(f\"Max Prime residuals end: {max(prime_residuals_np[-1])}\")\n",
    "print(f\"Max fixed residuals end: {max(fixed_residuals_np[-1])}\")\n",
    "print(f\"Min Prime residuals end: {min(prime_residuals_np[-1])}\")\n",
    "print(f\"Min fixed residuals end: {min(fixed_residuals_np[-1])}\")\n",
    "\n",
    "\n",
    "np.savetxt('results_{rnn}_inference/original_trajectory.csv', xi_np, delimiter=',')  # Save first sample\n",
    "np.savetxt('results_{rnn}_inference/projected_trajectory.csv', xi_filtered_np, delimiter=',')\n",
    "np.savetxt('results_{rnn}_inference/prime_residuals.csv', prime_residuals_np, delimiter=',')\n",
    "np.savetxt('results_{rnn}_inference/fixed_residuals.csv', fixed_residuals_np, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af24998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "#print(\"P_pos\", opt_class.P_pos)\n",
    "\n",
    "P_pos_np = model.P_pos.cpu().detach().numpy()\n",
    "print(\"P_pos\", P_pos_np.shape)\n",
    "print(\"xi_pos\", xi_filtered_np.shape)\n",
    "pos = (P_pos_np @ xi_filtered_np.T).T #+model.theta_init*np.ones((xi_filtered_np.shape[0], P_pos_np.shape[0]))\n",
    "pos_np = np.asarray(pos)\n",
    "#print(\"pos_np\", pos_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot(pos_np.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(2)\n",
    "plt.plot(xi_np.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0955a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.figure(3)\n",
    "plt.plot(xi_filtered_np.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af771c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_trajectory(original, projected, dof_idx=0, dof=1, dt=0.05):\n",
    "    \"\"\"Visualize original and residual trajectories separately for a specific DOF\"\"\"\n",
    "    \n",
    "    num_steps = original.shape[0] // dof\n",
    "    \n",
    "    # Extract velocities for the specified DOF\n",
    "    orig_vel = original[dof_idx*num_steps : (dof_idx+1)*num_steps]\n",
    "    proj_vel = projected[dof_idx*num_steps : (dof_idx+1)*num_steps]\n",
    "    \n",
    "    # Calculate residual velocity (original - projected)\n",
    "    filtered_vel = proj_vel\n",
    "    \n",
    "    # Create time vector\n",
    "    time = np.arange(num_steps) * dt\n",
    "    \n",
    "    # Plot original velocity\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(time, orig_vel, 'b-')\n",
    "    plt.axhline(y=1.0, color='g', linestyle='--', label='v_max')\n",
    "    plt.axhline(y=-1.0, color='g', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel(f'Joint {dof_idx} Velocity')\n",
    "    plt.title(f'Original Joint {dof_idx} Velocity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        plt.savefig(f\"original_trajectory_dof{dof_idx}.png\")\n",
    "        print(f\"Original plot saved as original_trajectory_dof{dof_idx}.png\")\n",
    "    \n",
    "    # Plot residual velocity\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(time, filtered_vel, 'm-')\n",
    "    plt.axhline(y=0.0, color='k', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel(f'Joint {dof_idx} Filtered Velocity')\n",
    "    plt.title(f'Filtered Velocity for Joint {dof_idx}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        plt.savefig(f\"residual_trajectory_dof{dof_idx}.png\")\n",
    "        print(f\"Residual plot saved as residual_trajectory_dof{dof_idx}.png\")\n",
    "\n",
    "\n",
    "def visualize_residuals(residuals):\n",
    "    \"\"\"Visualize residuals across iterations for a specific batch sample\"\"\"\n",
    "    \n",
    "    # residuals shape: (maxiter_projection, num_batch)\n",
    "    # Extract residuals for specific batch sample\n",
    "    \n",
    "    residuals_sample = residuals\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(residuals_sample, 'b-', marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.title(f'ADMM Residuals Convergence )')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        plt.savefig(f\"residuals_batch.png\")\n",
    "        print(f\"Residuals plot saved as residuals_batch.png\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc513c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "visualize_trajectory(xi_np.T, xi_filtered_np.T, dof_idx=0, dof=1, dt=0.05)\n",
    "visualize_residuals(prime_residuals_np)\n",
    "visualize_residuals(fixed_residuals_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start\n",
    "print(\"Start\")\n",
    "print(f\"Max Prime residuals start_{rnn}: {max(prime_residuals_np[0])}\")\n",
    "print(f\"Max fixed residuals start_{rnn}: {max(fixed_residuals_np[0])}\")\n",
    "print(f\"Min Prime residuals start_{rnn}: {min(prime_residuals_np[0])}\")\n",
    "print(f\"Min fixed residuals start_{rnn}: {min(fixed_residuals_np[0])}\")\n",
    "\n",
    "#End\n",
    "print(\"End\")\n",
    "print(f\"Max Prime residuals end_{rnn}: {max(prime_residuals_np[-1])}\")\n",
    "print(f\"Max fixed residuals end_{rnn}: {max(fixed_residuals_np[-1])}\")\n",
    "print(f\"Min Prime residuals end_{rnn}: {min(prime_residuals_np[-1])}\")\n",
    "print(f\"Min fixed residuals end_{rnn}: {min(fixed_residuals_np[-1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manipulator_torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
